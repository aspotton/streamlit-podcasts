{"podcast_details": {"podcast_title": "The AI Breakdown: Daily Artificial Intelligence News and Discussions", "episode_title": "AGI By 2032? The Most Interesting AI Predictions", "episode_image": "https://megaphone.imgix.net/podcasts/9ad36894-20f2-11ee-9d6c-d76aa9b66d23/image/BITCOIN_BUILDERS_3.png?ixlib=rails-4.3.1&max-w=3000&max-h=3000&fit=crop&auto=format,compress", "episode_transcript": " Today on the AI Breakdown, we're looking at what prediction markets think about key AI events. Before that on the Brief, Microsoft Azure releases a private version of ChatGPT. Or do they? The AI Breakdown is a daily podcast and video about the most important news and discussions in AI. Go to breakdown.network for more information about our Discord, our YouTube, and our newsletter. Welcome back to the AI Breakdown Brief, all the AI headline news you need in around five minutes. We kick off today with a story that harkens back to something that was announced a few months ago but has not materialized. One of the big concerns for enterprises using ChatGPT and tools like it is that their private data could be compromised. Now that could be in the form of OpenAI using data that is input into ChatGPT as part of the normal business usage for future model training. Or it could be even more egregious leaks. This is why numerous companies like Samsung have actually banned ChatGPT. Now to respond to this at the end of April, OpenAI announced a few different things. First, they created a private mode that allowed users to disable data storage for future training purposes. In other words, if you turned it off, OpenAI was saying that your chats would not be used to train future versions of the LLM. And as part of that same announcement, they also said, we are working on a new ChatGPT business subscription for professionals who need more control over their data, as well as enterprises seeking to manage their end users. ChatGPT business will follow our API's data usage policies, which means that end users data won't be used to train our models by default. We plan to make ChatGPT business available in the coming months. Well, that was in April and we haven't seen anything else about ChatGPT business since then. However, MSpoweruser.com just noticed that Azure is allowing ChatGPT within their enterprise network. The article reads, Microsoft uploaded Azure ChatGPT on GitHub and it's open source with private Azure hosting. If your company already uses Azure, then adding ChatGPT to it should not be very complicated. Now, the interesting thing is that when you click on the link, it appears not to be there, although a version is available on the way back machine from just yesterday. The GitHub page reads, Unleash the power of Azure OpenAI. ChatGPT has grown explosively in popularity, as we all know. Business users around the globe often tap into the public service to work more productively or act as a creative assistant. However, ChatGPT risks exposing confidential intellectual property. One option is to block corporate access to ChatGPT, but people always find workarounds. This also limits the powerful capabilities of ChatGPT and reduces employee productivity and their work experience. ChatGPT on Azure Solution Accelerator is our enterprise option. The solution provides similar user experience to ChatGPT, but offer it as your private ChatGPT. Now, one part of the conversation is around the strange relationship between OpenAI and Microsoft, where Microsoft is obviously OpenAI's biggest investor, but at the same time, the two tend to have competing solutions in certain areas. Is Azure's version of ChatGPT one of those frenemy-style competitions? Or was this actually pushed to GitHub in error? Is this a future product that wasn't ready for release that was pushed live anyways? Feels to me like there are a lot of questions, and it'll be interesting to see how the story plays out. Now, one possibility for why OpenAI has not pushed their ChatGPT business version yet might be the shortage of GPUs. OpenAI CEO Sam Altman has talked frequently about how many of their plans have been constrained by that shortage, although he hasn't specifically mentioned that business offering. We've also heard about companies in China racing to get their hands on GPUs, albeit the powered-down NVIDIA chips that were still okayed by the US government, even in the context of their China chip export restrictions. But now the Financial Times is reporting that Saudi Arabia and the UAE are also racing to acquire thousands of GPUs, given the global shortage. The Financial Times writes, Saudi Arabia has bought at least 3,000 of NVIDIA's H100 chips, a $40,000 processor described by NVIDIA chief Jensen Huang as the world's first computer chip designed for generative AI. According to the Financial Times sources, the Gulf states are basically trying to create their own models that they can use to create their own chips. The Gulf states are trying to create their own models that they can use to create their own chips. The Gulf states are trying to create their own models that they can use to create their own chips. The Gulf states are basically trying to create their own models that they have more control over. A person that Financial Times characterized as familiar with Abu Dhabi's thinking said, Basically, these Gulf states are trying to carve out some sort of AI non-alignment. Not everyone is super stoked on this. Averna McGowan, the director of the Center for Democracy and Technology said, Speaking of potentially not our favorite use cases for AI, Engadget is reporting that a clever Iowa school district is using the technology to find books that they might want to ban. You know, the big problem, of course, with book banning is that to know if you'd want to ban the books, you'd have to actually read them. Not anymore, thanks to artificial intelligence. Engadget writes, Now, it is probably too deep and political to get into a discussion of the rise of literary censorship in the United States. However, it is a great reminder, as always, that technologies are tools and they're going to be used by everyone for whatever purposes they already have. Finally, rounding the corner and closing out with some cool technology, I told you previous about Nvidia's Neuralangelo. It's a project that takes a 2D video as input, such as an object, monument, building or landscape, and then creates a 3D model around it. This is similar in some ways to neural radiance fields, but is in fact a slightly different type of technology. While excitingly to many, Nvidia has just open sourced that code, giving a much wider array of people the ability to play around with the technology. Lastly today, if you were wondering if maybe the news cycle has ebbed just a bit when it comes to AI, let me leave you with an announcement of an announcement. Humane is the buzzy AI startup that did a demo at TED earlier this year that included a projection onto the presenters hands that functioned just like a screen, as well as real-time translation in the voice of the speaker into a language that he didn't speak. And the reason that people are really excited about this is that it promises to be a completely different type of user interface experience. In other words, it's using AI to decouple people from screens, which is something that many are really excited about. Well, the company just dropped a video on its Discord that said that on the same day as a solar eclipse happens in October, October 14th, the humane AI pin will officially be unveiled. Founder Imran Chaudhry said, There's an incredible celestial event that's happening in October, an eclipse. An eclipse is an important symbol for us. It's a new beginning spiritually. That's what it means. It's something that the whole world notices and comes together. We are certainly looking forward to be able to have a special moment on that day. So if you are as well excited about this human AI pin, October 14th, put it on your calendar and we'll see you back here to cover whatever it is. Thanks as always for listening or watching and I'll be back soon with the main AI breakdown. Before we get into the main AI breakdown, I want to tell you about today's sponsor, Supermanage. If you work in a professional setting, you probably have some version of a one-on-one meeting either with the people that work for you or the people that you work with. Unfortunately, all too often, those one-on-one meetings become glorified catch-up calls. Don't you wish you could jump right to the stuff that really matters? That's where Supermanage comes in. Supermanage AI magically distills your team's public Slack channels into a real-time brief on any employee, anytime. Catch up on contributions, work in progress, challenges they're facing, sentiment, everything you need to show up ready for a truly meaningful conversation. And it's completely free. Visit supermanage.ai forward slash breakdown today to start making the most of your one-on-ones. And thanks again to Supermanage for sponsoring the AI breakdown. Welcome back to the AI breakdown. Today, we are looking at the collective intelligence around possible AI futures. Now, one of the things that's interesting about the artificial intelligence space is just how contentious, well, everything about it is. You have debates around policy, debates around safety questions, debates around technology, and all of that is happening in an incredibly fast-moving, fast-evolving context. Given that, it's very hard for any one person to know exactly how things are likely to proceed or what's likely to happen next. And in fact, one of the things that makes some people nervous about the development of the field is how bad experts have been, historically speaking, at predicting how quickly developments would happen. In other words, people by and large thought it was going to take a lot longer to get to the GPT-4 level intelligence that we're at than it actually took. So, of course, when the predictions of experts start to fail, an alternative approach is to look at collective intelligence. One really interesting resource for that is Metaculous. Metaculous calls themselves a forecasting platform that optimally aggregates quantitative predictions of future events. And earlier this week, the AI Safety Memes account posted a number of really interesting Metaculous prediction markets around AI. So what we're going to do today is head on over to Metaculous and look at some of the more interesting questions. Let's look at an AI business prediction market to get a sense for how the platform works. So the question, which was opened on April 19th, 2023, was, will an Elon Musk-funded AI lab release an LLM before 2024? As part of the prediction market, there's a section that articulates the resolution criteria. In this case, they write, this question will resolve as, yes, if an AI lab which receives funding from Elon Musk releases a large language model at any time between April 1st, 2023 and January 1st, 2024, a model will be considered released if a general member of the public can access the model either through a paid subscription, a waitlist or through immediate free access. There are no requirements on the amount of funding Elon Musk provides to the lab, so long as the information is public and not disputed by either Musk or the AI lab. Anyways, the point is not the details of this particular question, but that when a market is opened up, there are very, very specific resolution criteria that are included. Metaculous also has a section for background info to help people get a little bit more information. And then when you make a prediction, it's not necessarily a binary yes or no, but a probability distribution scale where you can say 1%, i.e. least likely, 99%, i.e. most likely, or anything in between. The chart at the top shows the results over time, including the aggregate prediction as well as the total number of forecasters. So, for example, on July 13th, there were 66 total forecasters and the community predicted a 32% chance that an Elon Musk funded AI lab would release an LLM before 2024. Just a couple days later, that had jumped to 50%. Perhaps not surprisingly, that number went up after XAI was announced formally. Okay, so that gives you a sense of how this works. Now Metaculous has a number of different buckets into which their prediction markets fit around AI. Those include AGI outcomes, regulation of AI, AI safety, AI demonstrations, business of AI, public perception of AI, AI in China, AI technical benchmarks, and public figure forecasts. I'm going to mostly skip over the AI technical benchmark section because it is, well, the most technical. It includes questions like, will transformer-derived architectures accelerate progress in deep learning? How many billions of parameters will the largest machine learning model trained before 2030 have? Will OpenAI release an LLM product or API that hallucinates 5x less than GPT-4 did when it was released by June 30th, 2025? Let's instead jump into the public perception of AI, and let's try to go to some of the most active conversations. One question that I think is interesting is will AI be meaningfully discussed by both candidates in the 2024 US presidential debate? The resolution criteria says that the question resolves yes if both Democratic and Republican candidates say at least two sentences largely about AI during the official 2024 presidential debates and otherwise resolves as no. Right now the community thinks there is a 73% chance of that. Now one big question is of course whether debates are actually held as they've sort of been on the chopping block for the last few years, but nevertheless assuming that they are, 73% of people think that AI will be a meaningful conversation point. Here's one that's pretty interesting and pretty far out there. When will most Americans personally know someone who has dated an AI? The weighted predictions of the community have this happening on April 6th, 2034. So basically 11 years from now, most Americans will personally know someone who has dated an AI. Now this also shows one other interesting feature of this platform, which is that over here on the right you can see news that relates to the prediction market, such as CNN's recent piece Modern Romance, Falling in Love with AI. Let's move over into the business of AI section. A lot of these have to do with competition in the AI space. For example, will Bing's search engine market share be at least 5% in March of 2024? For reference, their market share was around 3% in 2022. Only 7% of users predicted that it would. Meanwhile, when asked what the search engine market share of Bing will be in December of this year, the average prediction was 3.274%, which is a very small jump up from the 3.0% or so that it was last year. Another one about the arms race. When will Google DeepMind's Gemini model be publicly released? The average prediction is January 4th, 2024. Now DeepMind's Demis Hisabes has said that this model kicks the slats out of chat GPT's GPT-4 basically. So there's a fair bit of excitement around seeing what it can actually do. Related, when will OpenAI announce GPT-5? This is one of the more participated prediction markets around AI on Metaculous. And right now, the aggregate answer is December 13th, 2024. Now this one's interesting because there is not only a technical dimension to this, but also obviously a political dimension. I believe, and I think many others do as well, that it would be extremely problematic for OpenAI to announce GPT-5 right now, given big unanswered questions about policy approaches to highly powerful LLMs in the future. Speaking of policy and regulation, there are a lot of active markets around these questions. For example, will the US place restrictions on the total compute capacity individuals or companies are allowed to have before 2026? People give this one very low odds, just 3% think the US will. On the other end of the spectrum, on the question before 2025, will laws be in place requiring that AI systems that emulate humans must reveal to people that they are AI? The community prediction is a 75% chance that yes, they will. Here's another interesting one. Will a member of the United States Congress introduce legislation limiting the use of LLMs before January 1st, 2024? The community gives a prediction of a 64% chance of that. By the way, going back to that compute capacity question, if you zoom out to 2050, the community gives it a 39% chance that the United States will place restrictions on compute capacity eventually. There is also a ton of activity around the AI safety bucket. You remember that just a few weeks ago, OpenAI announced their Super Alignment Initiative. This is a sort of moonshot challenge to solve the core technical challenges of super intelligence alignment within the next four years. Of course, this made it to a prediction market. Will OpenAI announce that it has solved the core technical challenges of super intelligence alignment by June 30th, 2027? The community prediction ascribes that just a 9% chance. On the flip side, question, in 2023, will a successful deepfake attempt causing real damage make the front page of a major news source? That one's at 86% chance of happening. Another slightly nerve wracking one. Before 2032, will we see an event precipitated by AI malfunction that causes at least 100 deaths or at least $1 billion in economic damage? This one was actually opened all the way back in September of 2021 and has more or less been steadily increasing throughout that time. For much of 2022, the community prediction had between 50 and 60% odds of this happening, but now that number is up to 85%. And finally, let's close on AGI itself. Will there be human machine intelligence parity between 2040? This is one of the older questions on the platform being opened on December 1st, 2016. Interestingly, the forecast started high. In the first few months after the prediction market was created, the community ascribed between a 60 and 80% chance of this, although they went down between the end of 2017 and the end of 2018. In November 2018, for example, 295 forecasters had a 35% chance that there would be human machine intelligence parity before 2040. Over the course of 2020 and 2021, that ebbed and flowed, getting all the way back up to around 60% chance, before in early 2022 coming all the way back down to 32%. Over the course of 2022, however, that did nothing but increase. And after chat GPT was released at the end of the year, the predictions went through the roof. With over 2000 predictions, the community now ascribes it a 92% chance. But what about when? Well, there's a question, when will the first general AI system be devised, tested and publicly announced? The resolution criteria goes deep in terms of what this actually means, but effectively, it's the when to the answer of that question that we just discussed of human machine intelligence parity. The weighted community prediction has it happening on July 6, 2032. So around nine years away. There's also an interesting question comparing the relationship between weak AGI's and super intelligent AIs asking after a weak AGI is created, how many months will it be before the first super intelligent AIs created where the community is predicting 42.47 months, in other words, around three and a half years. So the point of all of this is obviously not to treat these predictions as definitive. And frankly, it's not even really to look at them as static predictions. What's far more interesting is to understand how things change over time and how new news influences or shapes or changes the story those prediction markets are telling us. Ultimately, resources like this are all about helping us get a pulse on an incredibly fast moving technology that is also going to have huge impacts on economy and society. If you want to go play around yourself, you can go to Metaculous.com. That's M-E-T-A-C-U-L-U-S.com. And it won't be hard for you to find AI. But if you want to just do slash AI that will get you to this section as well. Anyways, guys, hope this was interesting. And of course, let me know what your predictions are in the comments. Thanks as always for hanging out and until next time, peace."}, "podcast_summary": "In this episode of the AI Breakdown podcast, the host discusses various topics related to AI. Firstly, they talk about Microsoft Azure releasing a private version of ChatGPT, but they note that there is some confusion and uncertainty around its availability. They then move on to discussing prediction markets and how they can provide insights into the future of AI. The host explores different prediction markets on Metaculous, a forecasting platform, and highlights some interesting questions and predictions made by the community. They cover topics such as AI in politics, business competition, AI safety, and public perception of AI. The host emphasizes that these predictions are not definitive, but they offer valuable perspectives on the rapidly evolving AI landscape. The episode concludes by encouraging listeners to explore Metaculous and make their own predictions.", "podcast_guest": "Unspecified guest speaker", "podcast_highlights": "Key areas in the podcast include:\n\n1. Discussion about the concerns of enterprises using ChatGPT and the potential compromise of private data.\n2. OpenAI's announcement of a private mode and plans for a ChatGPT business subscription.\n3. The discovery of an Azure version of ChatGPT on GitHub, raising questions about the relationship between OpenAI and Microsoft.\n4. Mention of the shortage of GPUs and how it may delay the release of OpenAI's ChatGPT business version.\n5. Reports of Saudi Arabia and the UAE racing to acquire GPUs due to the global shortage.\n6. The use of AI in an Iowa school district to find books that they might want to ban.\n7. The open-sourcing of Nvidia's Neuralangelo code, allowing more people to experiment with the technology.\n8. A discussion on Metaculous, a forecasting platform that aggregates quantitative predictions about AI futures.\n9. Various prediction markets on Metaculous, including AI business, public perception of AI, AI safety, and AI regulation.\n10. Notable predictions in the markets, including the release of GPT-5, major AI safety incidents, and human-machine intelligence parity.\n11. Mention of the AI startup Humane and their upcoming announcement of the humane AI pin.\n\nOverall, the podcast covers updates and developments in the AI industry, as well as explores predictions and debates around various AI-related topics."}